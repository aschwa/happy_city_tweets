{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T21:16:17.530664Z",
     "start_time": "2020-03-03T21:16:17.491992Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "from src.func import tweet_utils\n",
    "from src.func import regex\n",
    "from src.func import labmtgen\n",
    "from src.sentiment.senti_utils import *\n",
    "#from src.scripts.process_tweets import *\n",
    "from labMTsimple.storyLab import *\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through cities\n",
    "tweet_dir= Path(\"../data/processed/park_user_tweets\")\n",
    "cities = list(tweet_dir.glob(\"*.json\"))\n",
    "\n",
    "## load all stop wordds\n",
    "stop_file = Path(\"../src/sentiment/city_stops.json\")\n",
    "with open(stop_file, 'r') as fp:\n",
    "    stop_dict  = json.load(fp)\n",
    "\n",
    "## load park type file\n",
    "park_info = pd.read_csv('../data/processed/tpl/park_info_size.csv',dtype=str)\n",
    "\n",
    "cats = ['acres_1_10', 'acres_gt_100', 'acres_10_100', 'acres_lt_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_tweets_bytype = {cat:[] for cat in cats}\n",
    "time_tweets_bytype = {cat:[] for cat in cats}\n",
    "park_stops = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParkID</th>\n",
       "      <th>Park_Place</th>\n",
       "      <th>Park_Pla_1</th>\n",
       "      <th>Park_Desig</th>\n",
       "      <th>Park_Size_</th>\n",
       "      <th>size_cat</th>\n",
       "      <th>park_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24040000001</td>\n",
       "      <td>Baltimore city</td>\n",
       "      <td>2404000</td>\n",
       "      <td>LP</td>\n",
       "      <td>0.168728709898</td>\n",
       "      <td>acres_lt_1</td>\n",
       "      <td>local_park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24040000002</td>\n",
       "      <td>Baltimore city</td>\n",
       "      <td>2404000</td>\n",
       "      <td>LP</td>\n",
       "      <td>0.622870976624</td>\n",
       "      <td>acres_lt_1</td>\n",
       "      <td>local_park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24040000003</td>\n",
       "      <td>Baltimore city</td>\n",
       "      <td>2404000</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.3572710309</td>\n",
       "      <td>acres_1_10</td>\n",
       "      <td>local_park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24040000004</td>\n",
       "      <td>Baltimore city</td>\n",
       "      <td>2404000</td>\n",
       "      <td>LP</td>\n",
       "      <td>0.992805422216</td>\n",
       "      <td>acres_lt_1</td>\n",
       "      <td>local_park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24040000005</td>\n",
       "      <td>Baltimore city</td>\n",
       "      <td>2404000</td>\n",
       "      <td>LP</td>\n",
       "      <td>1.72528447101</td>\n",
       "      <td>acres_1_10</td>\n",
       "      <td>local_park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ParkID      Park_Place Park_Pla_1 Park_Desig      Park_Size_  \\\n",
       "0  24040000001  Baltimore city    2404000         LP  0.168728709898   \n",
       "1  24040000002  Baltimore city    2404000         LP  0.622870976624   \n",
       "2  24040000003  Baltimore city    2404000         LP    1.3572710309   \n",
       "3  24040000004  Baltimore city    2404000         LP  0.992805422216   \n",
       "4  24040000005  Baltimore city    2404000         LP   1.72528447101   \n",
       "\n",
       "     size_cat   park_type  \n",
       "0  acres_lt_1  local_park  \n",
       "1  acres_lt_1  local_park  \n",
       "2  acres_1_10  local_park  \n",
       "3  acres_lt_1  local_park  \n",
       "4  acres_1_10  local_park  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "park_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>park_id</th>\n",
       "      <th>size_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24040000001</td>\n",
       "      <td>acres_lt_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24040000002</td>\n",
       "      <td>acres_lt_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24040000003</td>\n",
       "      <td>acres_1_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24040000004</td>\n",
       "      <td>acres_lt_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24040000005</td>\n",
       "      <td>acres_1_10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       park_id    size_cat\n",
       "0  24040000001  acres_lt_1\n",
       "1  24040000002  acres_lt_1\n",
       "2  24040000003  acres_1_10\n",
       "3  24040000004  acres_lt_1\n",
       "4  24040000005  acres_1_10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkcols = park_info[['ParkID', 'size_cat']].copy()\n",
    "parkcols.columns = ['park_id','size_cat']\n",
    "parkcols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City: ../data/processed/park_user_tweets/CO_Denver_0820000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CO_Denver_0820000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CO_Denver_0820000.json -acres_lt_1 33 tweets\n",
      "City: ../data/processed/park_user_tweets/CO_Denver_0820000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/AZ_Phoenix_0455000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/AZ_Phoenix_0455000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/AZ_Phoenix_0455000.json -acres_lt_1 6 tweets\n",
      "City: ../data/processed/park_user_tweets/AZ_Phoenix_0455000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/FL_Jacksonville_1235000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/FL_Jacksonville_1235000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/FL_Jacksonville_1235000.json -acres_lt_1 38 tweets\n",
      "City: ../data/processed/park_user_tweets/FL_Jacksonville_1235000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Austin_4805000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Austin_4805000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Austin_4805000.json -acres_lt_1 148 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Austin_4805000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Fort_Worth_4827000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Fort_Worth_4827000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Fort_Worth_4827000.json -acres_lt_1 16 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Fort_Worth_4827000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_El_Paso_4824000.json -acres_gt_100 225 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_El_Paso_4824000.json -acres_1_10 299 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_El_Paso_4824000.json -acres_lt_1 32 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_El_Paso_4824000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Diego_0666000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Diego_0666000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Diego_0666000.json -acres_lt_1 231 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Diego_0666000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TN_Memphis_4748000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TN_Memphis_4748000.json -acres_1_10 253 tweets\n",
      "City: ../data/processed/park_user_tweets/TN_Memphis_4748000.json -acres_lt_1 58 tweets\n",
      "City: ../data/processed/park_user_tweets/TN_Memphis_4748000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/DC_Washington_1150000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/DC_Washington_1150000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/DC_Washington_1150000.json -acres_lt_1 500 tweets\n",
      "City: ../data/processed/park_user_tweets/DC_Washington_1150000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/WA_Seattle_5363000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/WA_Seattle_5363000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/WA_Seattle_5363000.json -acres_lt_1 500 tweets\n",
      "City: ../data/processed/park_user_tweets/WA_Seattle_5363000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/IL_Chicago_1714000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/IL_Chicago_1714000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/IL_Chicago_1714000.json -acres_lt_1 500 tweets\n",
      "City: ../data/processed/park_user_tweets/IL_Chicago_1714000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Houston_4835000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Houston_4835000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Houston_4835000.json -acres_lt_1 105 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Houston_4835000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/MA_Boston_2507000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/MA_Boston_2507000.json -acres_lt_1 500 tweets\n",
      "City: ../data/processed/park_user_tweets/MA_Boston_2507000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/MA_Boston_2507000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/MI_Detroit_2622000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/MI_Detroit_2622000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/MI_Detroit_2622000.json -acres_lt_1 223 tweets\n",
      "City: ../data/processed/park_user_tweets/MI_Detroit_2622000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/NC_Charlotte_3712000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/NC_Charlotte_3712000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/NC_Charlotte_3712000.json -acres_lt_1 7 tweets\n",
      "City: ../data/processed/park_user_tweets/NC_Charlotte_3712000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/NY_New_York_3651000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/NY_New_York_3651000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/NY_New_York_3651000.json -acres_lt_1 500 tweets\n",
      "City: ../data/processed/park_user_tweets/NY_New_York_3651000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/IN_Indianapolis_1836003.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/IN_Indianapolis_1836003.json -acres_lt_1 116 tweets\n",
      "City: ../data/processed/park_user_tweets/IN_Indianapolis_1836003.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/IN_Indianapolis_1836003.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_San_Antonio_4865000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_San_Antonio_4865000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_San_Antonio_4865000.json -acres_lt_1 104 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_San_Antonio_4865000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Dallas_4819000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Dallas_4819000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Dallas_4819000.json -acres_lt_1 310 tweets\n",
      "City: ../data/processed/park_user_tweets/TX_Dallas_4819000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/OH_Columbus_3918000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/OH_Columbus_3918000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/OH_Columbus_3918000.json -acres_lt_1 109 tweets\n",
      "City: ../data/processed/park_user_tweets/OH_Columbus_3918000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/PA_Philadelphia_4260000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/PA_Philadelphia_4260000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/PA_Philadelphia_4260000.json -acres_lt_1 500 tweets\n",
      "City: ../data/processed/park_user_tweets/PA_Philadelphia_4260000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_Los_Angeles_0644000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_Los_Angeles_0644000.json -acres_lt_1 451 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_Los_Angeles_0644000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_Los_Angeles_0644000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/MD_Baltimore_2404000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/MD_Baltimore_2404000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/MD_Baltimore_2404000.json -acres_lt_1 486 tweets\n",
      "City: ../data/processed/park_user_tweets/MD_Baltimore_2404000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Jose_0668000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Jose_0668000.json -acres_lt_1 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Jose_0668000.json -acres_10_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Jose_0668000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Francisco_0667000.json -acres_gt_100 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Francisco_0667000.json -acres_1_10 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Francisco_0667000.json -acres_lt_1 500 tweets\n",
      "City: ../data/processed/park_user_tweets/CA_San_Francisco_0667000.json -acres_10_100 500 tweets\n"
     ]
    }
   ],
   "source": [
    "for city in cities:\n",
    "    park_stops = []\n",
    "    with open(city, 'r') as f:\n",
    "        park_user_tweets = json.load(f)\n",
    "    tweets_w_parks = get_time_control_text_park(park_user_tweets)\n",
    "    tweet_df = pd.DataFrame.from_dict(tweets_w_parks,dtype=str)\n",
    "    tweet_df = pd.merge(tweet_df,parkcols,how='left',on='park_id')\n",
    "    cats = list(set(tweet_df.size_cat.values))\n",
    "    park_list = list(set(tweet_df.park_name))\n",
    "    park_stops += get_park_stopwords(park_list)\n",
    "    for cat in cats:\n",
    "        tweet_subset = tweet_df[tweet_df.size_cat == cat]\n",
    "        n = min(500, len(tweet_subset))\n",
    "        print(\"City: {} -{} {} tweets\".format(city, cat, n))\n",
    "        index_list = range(len(tweet_subset))\n",
    "        sample = random.sample(index_list, n)\n",
    "        park_text = list(tweet_subset.park_text.values)\n",
    "        control_text = list(tweet_subset.control_text.values)\n",
    "        park_tweet_sample = [park_text[i] for i in sample]\n",
    "        control_tweet_sample = [control_text[i] for i in sample]\n",
    "        park_tweets_bytype[cat] += park_tweet_sample\n",
    "        time_tweets_bytype[cat] += control_tweet_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acres_1_10 12052\n",
      "acres_gt_100 12225\n",
      "acres_10_100 12500\n",
      "acres_lt_1 6473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check length of < 1 ..park_tweets_bytype = {cat:[] for cat in cats}\n",
    "for park_type,tweets in park_tweets_bytype.items():\n",
    "    print(park_type,len(tweets))\n",
    "\n",
    "len(park_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save each thing to a sample folder with name of date sample was run (user control tweet may change each time)\n",
    "today = \"0513\"\n",
    "results_dir = Path(\"../data/processed/combined_tweets/tweet_samples_{}\".format(today))\n",
    "with open(results_dir/Path(\"park_tweets_bytype.json\"), 'w') as fp:\n",
    "    json.dump(park_tweets_bytype,fp)\n",
    "with open(results_dir/Path(\"time_tweets_bytype.json\"), 'w') as fp:\n",
    "    json.dump(time_tweets_bytype,fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "## load frequent stop words  stop words\n",
    "stop_file = Path(\"../src/sentiment/city_stops.json\")\n",
    "with open(stop_file, 'r') as fp:\n",
    "    stop_dict  = json.load(fp)\n",
    "    \n",
    "#load stop words selected from raw wordshifts for probelmatic words\n",
    "freq_stops = []\n",
    "for city, words in stop_dict.items():\n",
    "    freq_stops+=words\n",
    "freq_stops.append('park')\n",
    "freq_stops = list(set(freq_stops))\n",
    "\n",
    "# combine with  names of parks\n",
    "all_stops = freq_stops + park_stops\n",
    "\n",
    "\n",
    "# put through ngram filter, lower\n",
    "all_stops = list(set([x.lower() for x in dict(regex.get_ngrams(' '.join(all_stops), path='../src/func/ngrams.bin')).keys()]))\n",
    "print(len(all_stops))\n",
    "# select ones with valence below 4 or greater than 6\n",
    "stops_w_val=[]\n",
    "words = labmtgen.load_labmt_words(\"../data/raw/data_labmt_simple.txt\")\n",
    "senti_dict = words.set_index('Word').to_dict()['Happs']\n",
    "for stop in all_stops:\n",
    "    if stop in senti_dict.keys():\n",
    "        val = senti_dict[stop]\n",
    "        if val <= 4.0 or val >= 6.0:\n",
    "            #count+=1\n",
    "            stops_w_val.append(stop)\n",
    "            #print(stop,senti_dict[stop])\n",
    "# check how #many of stop words are in labmt outside 4-6 range\n",
    "print(len(stops_w_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "for cat in cats:\n",
    "    results_dict[cat] = bootstrap_sentiment(park_tweets_bytype[cat], time_tweets_bytype[cat], stops_w_val,sample=.8,runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acres_1_10': [0.11472264350773287,\n",
       "  0.12461761098934154,\n",
       "  0.12551167431450327,\n",
       "  0.12805631864760603,\n",
       "  0.12252351593659228],\n",
       " 'acres_gt_100': [0.13084495336498048,\n",
       "  0.12705553664694236,\n",
       "  0.12880077497983056,\n",
       "  0.13220354221293285,\n",
       "  0.12786786043383636],\n",
       " 'acres_10_100': [0.07961949429900717,\n",
       "  0.07756543958249118,\n",
       "  0.08337921863665088,\n",
       "  0.06752940800897456,\n",
       "  0.08438186476866871],\n",
       " 'acres_lt_1': [0.09425190880783951,\n",
       "  0.1026447778398003,\n",
       "  0.10307146959840985,\n",
       "  0.1039210558804804,\n",
       "  0.09764765382976748]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/city_combined_0421/bootstrap_parktype.json','w') as fp:\n",
    "    json.dump(results_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_freq = {}\n",
    "\n",
    "for cat in cats:\n",
    "    results_dict_freq[cat] = bootstrap_sentiment(park_tweets_bytype[cat], time_tweets_bytype[cat], freq_stops,sample=.8,runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_dict_freq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d1c12a52fe34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_dict_freq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results_dict_freq' is not defined"
     ]
    }
   ],
   "source": [
    "results_dict_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
